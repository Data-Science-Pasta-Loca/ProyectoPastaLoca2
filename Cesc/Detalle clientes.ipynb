{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estructura de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cash_Request (CR)\n",
    "\n",
    "##### CR.Status (23970 registros)\n",
    "\n",
    "- **money_back**: 16397 registros. El CR fue reembolsado exitosamente.(The CR was successfully reimbursed.)\n",
    "---\n",
    "- **active**: 59 registros. Los fondos fueron recibidos en la cuenta del cliente. (Funds were received on the customer account.)\n",
    "- **direct_debit_sent**: 34 registros. Se envió un débito directo SEPA, pero aún no se confirma el resultado. (We sent/scheduled a SEPA direct debit to charge the customer account. The result of this debit is not yet confirmed)\n",
    "---\n",
    "- **rejected**: 6568 registros. El CR necesitó una revisión manual y fue rechazado. (The CR needed a manual review and was rejected)\n",
    "- **direct_debit_rejected**: 831 registros. El intento de débito directo SEPA falló. (Our last attempt of SEPA direct debit to charge the customer was rejected )\n",
    "- **transaction_declined**: 48 registros. No se pudo enviar el dinero al cliente. (We failed to send the funds to the customer) \n",
    "- **canceled**: 33 registros. El usuario no confirmó el CR en la app, fue cancelado automáticamente. (The user didn't confirm the cash request in-app, we automatically canceled it)\n",
    "\n",
    "---\n",
    "**En los datos proporcionados, NO aparecen los valores:** \n",
    "- approved : CR is a 'regular' one (= without fees) and was approved either automatically or manually. Funds will be sent aprox. 7 days after the creation\n",
    "- money_sent : We transferred the fund to the customer account. Will change to active once we detect that the user received the funds (using user's bank history)\n",
    "- pending : The CR is pending a manual review from an analyst\n",
    "- waiting_user_confirmation : The user needs to confirm in-app that he want the CR (for legal reasons)\n",
    "- waiting_reimbursement : We were not able to estimate a date of reimbursement, the user needs to choose one in the app.\n",
    "\n",
    "\n",
    "##### CR.Transfer Type\n",
    "\n",
    "- **instant**: El usuario eligió recibir el adelanto instantáneamente. (user choose not received the advance instantly)\n",
    "- **regular**: El usuario eligió no pagar inmediatamente y esperar la transferencia. (user choose to not pay and wait for the transfer)\n",
    "\n",
    "\n",
    "##### CR.Recovery Status\n",
    "\n",
    "- **null**: El CR nunca tuvo un incidente de pago.\n",
    "- **completed**: El incidente de pago fue resuelto (el CR fue reembolsado).\n",
    "---\n",
    "- **pending**: El incidente de pago aún está abierto.\n",
    "- **pending_direct_debit**: El incidente de pago sigue abierto, pero se ha lanzado un débito directo SEPA.\n",
    "\n",
    "\n",
    "### Fees (FE)\n",
    "\n",
    "##### FE.Type\n",
    "\n",
    "- **instant_payment**: Fees por adelanto instantáneo. (fees for instant cash request (send directly after user's request, through SEPA Instant Payment) )\n",
    "- **split_payment**: Fees por pago fraccionado (en caso de un incidente). (futures fees for split payment (in case of an incident, we'll soon offer the possibility to our users to reimburse in multiples installements))\n",
    "- **incident**: Fees por fallos de reembolsos. (fees for failed reimbursement. Created after a failed direct debit)\n",
    "- **postpone**: Fees por la solicitud de posponer un reembolso. (fees created when a user want to postpone the reimbursment of a CR)\n",
    "\n",
    "##### FE.Status (= does the fees was successfully charged)\n",
    "\n",
    "- **accepted**: El fee fue cobrado exitosamente. (fees were successfully charged)\n",
    "- **confirmed**: El usuario completó una acción que creó un fee. (the user made an action who created a fee. It will normally get charged at the moment of the CR's reimbursement. In some rare cases, postpones are confirmed without being charges due to a commercial offer.)\n",
    "---\n",
    "- **rejected**: El último intento de cobrar el fee falló. (the last attempt to charge the fee failed.)\n",
    "- **cancelled**: El fee fue creado pero cancelado por algún motivo. (fee was created and cancelled for some reasons. It's used to fix issues with fees but it mainly concern postpone fees who failed. We are charging the fees at the moment of the postpone request. If it failed, the postpone is not accepted and the reimbursement date still the same.)\n",
    "\n",
    "##### FE.Category\n",
    "\n",
    "- **rejected_direct_debit**: Fees creados cuando el banco del usuario rechaza el primer débito directo. (fees created when user's bank rejects the first direct debit)\n",
    "- **month_delay_on_payment**: Fees creados cada mes hasta que el incidente se cierre. (fees created every month until the incident is closed)\n",
    "---\n",
    "- **null**: No figura a la documentacio\n",
    "\n",
    "##### FE.paid_at:\t\n",
    "\n",
    "- Timestamp of the fee's payment\n",
    "\n",
    "##### FE.charge_moment (When the fee will be charge).\n",
    "\n",
    "- **before**: El fee se cobra en el momento de su creación. (the fee should be charged at the moment of its creation)\n",
    "- **after**: El fee se cobra cuando el CR es reembolsado. (the fee should be charged at the moment of the CR's reimbursement)\n",
    "\n",
    "##### FE.total_amount\n",
    "\n",
    "- Amount of the fee (including VAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Casos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import itertools # Importando itertools para generar combinaciones de columnas\n",
    "# Importando la función seasonal_decompose para la descomposición de series temporales\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.patches as mpatches\n",
    "import payments_manager as pm\n",
    "#pm.help()\n",
    "#pm.reset()\n",
    "#pm.init() #debug=True)\n",
    "cr_cp = pm.df('cr_cp')\n",
    "fe_cp = pm.df('fe_cp')\n",
    "#cr_cp.info()\n",
    "#fe_cp.info()\n",
    "\n",
    "df_jo = pm.df('df_jo')\n",
    "#df_jo.info()\n",
    "df_jo = pm.sort(\"df_jo\", [\"id_cr\"]).reset_index()\n",
    "df_jo = df_jo.drop(columns=['index'])\n",
    "\n",
    "#df_jo = df_jo.drop(columns=['Mes_created_at'])\n",
    "df_jo_cp = df_jo.copy()\n",
    "df_jo_cp['cr_received_date'] = df_jo_cp.cash_request_received_date\n",
    "#df_jo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_jo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "df = pm.df('df_jo')\n",
    "\n",
    "# send_at mirar si tiene registros faltantes.\n",
    "# money_back_date\n",
    "\n",
    "#0 registros\n",
    "#display(df[ (df['reimbursement_date'].isna()) & (df['stat_cr'] == 'money_back') ])\n",
    "\n",
    "\n",
    "#191 registros\n",
    "#display(df[ ((df['reimbursement_date'].isna()) | (df['money_back_date'].isna())) & (df['stat_cr'] == 'money_back') ])\n",
    "\n",
    "#191 Normalizamos:\n",
    "display(df[ (df['money_back_date'].isna()) & (df['stat_cr'] == 'money_back') ])\n",
    "df['money_back_date'] = df.apply(\n",
    "            lambda row: row['reimbursement_date']             \n",
    "            if ( pd.isna(row['money_back_date']) & (row['stat_cr'] == 'money_back') ) \n",
    "            else row['money_back_date'], axis=1)\n",
    "display(df[ (df['money_back_date'].isna()) & (df['stat_cr'] == 'money_back') ])\n",
    "\n",
    "# 838  registros\n",
    "#display(df[ (df['reimbursement_date'].notna()) & (df['money_back_date'].notna() & (df['stat_cr'] != 'money_back') )])#.head(5).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_cr = ['approved', 'money_sent', 'pending', 'direct_debit_sent', 'active', 'money_back']\n",
    "good_fe = ['confirmed', 'accepted']\n",
    "df_jo['good'] = (df_jo['stat_cr'].isin(good_cr)) & (df_jo['stat_fe'].isin(good_fe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_jo[df_jo.user_id ==2002].reset_index().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "df = pm.df('df_jo')\n",
    "#df.info()\n",
    "\n",
    "df_cr = pm.df('cr_cp')\n",
    "df_cr.info()\n",
    "\n",
    "grouped_counts = df.groupby(\n",
    "    ['id_cr']).size().reset_index(name='counts').sort_values(\n",
    "    by=['counts'], ascending=[False]).reset_index(drop=True)\n",
    "grouped_counts.info()\n",
    "display(grouped_counts.head(10))\n",
    "\n",
    "\n",
    "grouped_counts = df.groupby(\n",
    "    ['id_cr','user_id','stat_fe','stat_cr', 'transfer_type', 'type']).size().reset_index(name='counts').sort_values(\n",
    "    by=['counts'], ascending=[False]).reset_index(drop=True)\n",
    "grouped_counts.info()\n",
    "display(grouped_counts.head(10))\n",
    "\n",
    "grouped_counts = df.query('stat_fe == \"accepted\" & stat_cr == \"money_back\"').groupby(\n",
    "    ['id_cr','user_id','stat_fe','stat_cr', 'type']).size().reset_index(name='counts').sort_values(\n",
    "    by=['counts'], ascending=[False]).reset_index(drop=True)\n",
    "#display(grouped_counts.head(10))\n",
    "\n",
    "\n",
    "grouped_counts = df.query('stat_fe == \"accepted\" & stat_cr != \"money_back\"').groupby(\n",
    "    ['id_cr','user_id','stat_fe','stat_cr', 'type']).size().reset_index(name='counts').sort_values(\n",
    "    by=['counts'], ascending=[False]).reset_index(drop=True)\n",
    "grouped_counts.info()\n",
    "#display(grouped_counts.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-filtrar el dataframe para simplificar cálculos\n",
    "df_filtered = df_jo[\n",
    "    (df_jo['stat_fe'] == \"accepted\") | (df_jo['stat_cr'] == \"money_back\")\n",
    "]\n",
    "\n",
    "# Agregar columnas auxiliares para evitar cálculos repetitivos\n",
    "df_filtered['accepted_fee'] = df_filtered.apply(\n",
    "    lambda row: row['fee'] if row['stat_fe'] == \"accepted\" else 0, axis=1\n",
    ")\n",
    "df_filtered['money_back_amount'] = df_filtered.apply(\n",
    "    lambda row: row['amount'] if row['stat_cr'] == \"money_back\" else 0, axis=1\n",
    ")\n",
    "df_filtered['money_back_id'] = df_filtered.apply(\n",
    "    lambda row: row['id_cr'] if row['stat_cr'] == \"money_back\" else None, axis=1\n",
    ")\n",
    "\n",
    "# Agrupamiento optimizado\n",
    "cohort_analysis_2 = df_filtered.groupby(['user_id', 'Mes_created_at'], as_index=False).agg(\n",
    "    total_paid_fees=('accepted_fee', 'sum'),\n",
    "    total_paid_cr=('money_back_amount', 'sum'),\n",
    "    Num_Solicitudes=('money_back_id', 'nunique')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_analysis_2 = (\n",
    "    df_jo.query('stat_fe == \"accepted\" | stat_cr == \"money_back\"')\n",
    "        .groupby(['user_id', 'Mes_created_at'], as_index=False)\n",
    "        .agg(\n",
    "            total_paid_fees=('fee', lambda x: x[df_jo.loc[x.index, 'stat_fe'] == 'accepted'].sum()),            \n",
    "            # Contar los valores únicos de 'stat_cr' donde su valor sea 'money_back'\n",
    "            total_paid_cr=('amount', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].unique().sum()),\n",
    "            # Contar los valores únicos de 'id_cr' donde 'stat_cr' es igual a 'money_back'\n",
    "            Num_Solicitudes=('id_cr', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].nunique())\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cohort_analysis_2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_analysis_2 = (\n",
    "    df_jo.query('stat_fe == \"accepted\" | stat_cr == \"money_back\"')\n",
    "        .groupby(['user_id', 'Mes_created_at'], as_index=False)\n",
    "        .agg(\n",
    "            # #total_paid_fees=('fee', 'sum'),            \n",
    "            # #Num_Solicitudes=('id_cr', 'nunique')\n",
    "            # #Num_Solicitudes=('id_cr', lambda x: x.unique().sum())\n",
    "            # Num_Solicitudes=('id_cr', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].nunique())\n",
    "\n",
    "            total_paid_fees=('fee', lambda x: x[df_jo.loc[x.index, 'stat_fe'] == 'accepted'].sum()),            \n",
    "            # Contar los valores únicos de 'stat_cr' donde su valor sea 'money_back'\n",
    "            total_paid_cr=('amount', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].unique().sum()),\n",
    "            # Contar los valores únicos de 'id_cr' donde 'stat_cr' es igual a 'money_back'\n",
    "            Num_Solicitudes=('id_cr', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].nunique())\n",
    "        )\n",
    ")\n",
    "# Restablecer el índice para un DataFrame limpio (opcional, ya garantizado por as_index=False)\n",
    "cohort_analysis_2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Calcular el índice como porcentaje entre 'total_paid_fees' y 'total_paid_cr'\n",
    "cohort_analysis_2['index'] = (\n",
    "    cohort_analysis_2['total_paid_fees'] / cohort_analysis_2['total_paid_cr'] ) * 100\n",
    "\n",
    "# Reemplazar valores 'inf' con 0 para manejar divisiones por cero\n",
    "cohort_analysis_2['index'] = cohort_analysis_2['index'].replace(np.inf, 0)\n",
    "\n",
    "# Calcular la fecha del último pedido por usuario a partir del DataFrame original\n",
    "df_jo['created_at'] = pd.to_datetime(df_jo['created_at'])  # Asegurarse de que el formato sea datetime\n",
    "last_order_per_user = (\n",
    "    df_jo.groupby('user_id')['created_at']\n",
    "    .max()  # Obtener la fecha más reciente de pedido para cada usuario\n",
    "    .dt.to_period('M')  # Convertir a periodo mensual\n",
    "    .reset_index()  # Restablecer el índice para facilitar el merge\n",
    ")\n",
    "\n",
    "# Incorporar la fecha del último pedido en el DataFrame de análisis de cohortes\n",
    "cohort_analysis_2 = pd.merge(\n",
    "    cohort_analysis_2,\n",
    "    last_order_per_user.rename(columns={'created_at': 'last_order'}),\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "display(cohort_analysis_2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-filtrar el dataframe para simplificar cálculos\n",
    "df_filtered = df_jo[\n",
    "    (df_jo['stat_fe'] == \"accepted\") | (df_jo['stat_cr'] == \"money_back\")\n",
    "]\n",
    "\n",
    "# Agregar columnas auxiliares para evitar cálculos repetitivos\n",
    "df_filtered['accepted_fee'] = df_filtered.apply(\n",
    "    lambda row: row['fee'] if row['stat_fe'] == \"accepted\" else 0, axis=1\n",
    ")\n",
    "df_filtered['money_back_amount'] = df_filtered.apply(\n",
    "    lambda row: row['amount'] if row['stat_cr'] == \"money_back\" else 0, axis=1\n",
    ")\n",
    "df_filtered['money_back_id'] = df_filtered.apply(\n",
    "    lambda row: row['id_cr'] if row['stat_cr'] == \"money_back\" else None, axis=1\n",
    ")\n",
    "\n",
    "# Agrupamiento optimizado\n",
    "cohort_analysis_2 = df_filtered.groupby(['user_id', 'Mes_created_at'], as_index=False).agg(\n",
    "    total_paid_fees=('accepted_fee', 'sum'),\n",
    "    total_paid_cr=('money_back_amount', 'sum'),\n",
    "    Num_Solicitudes=('money_back_id', 'nunique')\n",
    ")\n",
    "\n",
    "# Restablecer el índice para un DataFrame limpio (opcional, ya garantizado por as_index=False)\n",
    "cohort_analysis_2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Calcular el índice como porcentaje entre 'total_paid_fees' y 'total_paid_cr'\n",
    "cohort_analysis_2['index'] = (\n",
    "    cohort_analysis_2['total_paid_fees'] / cohort_analysis_2['total_paid_cr'] ) * 100\n",
    "\n",
    "# Reemplazar valores 'inf' con 0 para manejar divisiones por cero\n",
    "cohort_analysis_2['index'] = cohort_analysis_2['index'].replace(np.inf, 0)\n",
    "\n",
    "# Calcular la fecha del último pedido por usuario a partir del DataFrame original\n",
    "df_jo['created_at'] = pd.to_datetime(df_jo['created_at'])  # Asegurarse de que el formato sea datetime\n",
    "last_order_per_user = (\n",
    "    df_jo.groupby('user_id')['created_at']\n",
    "    .max()  # Obtener la fecha más reciente de pedido para cada usuario\n",
    "    .dt.to_period('M')  # Convertir a periodo mensual\n",
    "    .reset_index()  # Restablecer el índice para facilitar el merge\n",
    ")\n",
    "\n",
    "# Incorporar la fecha del último pedido en el DataFrame de análisis de cohortes\n",
    "cohort_analysis_2 = pd.merge(\n",
    "    cohort_analysis_2,\n",
    "    last_order_per_user.rename(columns={'created_at': 'last_order'}),\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "display(cohort_analysis_2.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 102105])\n",
    "\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 16391])\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 2002])\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 13851])\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 1987]) #.tail(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 102105])\n",
    "\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 16391])\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 2002])\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 13851])\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 1987]) #.tail(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = None\n",
    "tops = df_jo[df_jo['stat_cr' ]== 'money_back'].groupby('user_id').agg(fees=('fee','sum'))\n",
    "tops = df_jo[df_jo['stat_fe'] == 'accepted'  ].groupby('user_id').agg(fees=('fee','sum'))\n",
    "#display(df_jo[tops])\n",
    "top_users = tops.sort_values(by='fees', ascending=False).iloc[:10].reset_index()\n",
    "display(top_users)\n",
    "#top_users = tops.sort_values(by='fees', ascending=True).iloc[:10]\n",
    "#display(top_users)\n",
    "\n",
    "#display(df_jo[top_users])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pm.df('df_jo')\n",
    "timeFormat ='S' #D\n",
    "df['created_at'] = df['created_at'].dt.to_period(timeFormat) #'Min')\n",
    "df['created_at_fe'] = df['created_at_fe'].dt.to_period(timeFormat) #'Min')\n",
    "df['updated_at'] = df['updated_at'].dt.to_period(timeFormat) #'Min')\n",
    "#df['to_receive_ini'] = df['to_receive_ini'].timedelta(seconds=math.ceil(df['to_receive_ini'].total_seconds()))\n",
    "df['to_receive_ini'] = pd.to_timedelta(df['to_receive_ini']).round(timeFormat)\n",
    "df['to_receive_bank'] = pd.to_timedelta(df['to_receive_bank']).round(timeFormat)\n",
    "df['to_reimbur'] = pd.to_timedelta(df['to_reimbur']).round(timeFormat)\n",
    "df['to_reimbur_cash'] = pd.to_timedelta(df['to_reimbur_cash']).round(timeFormat)\n",
    "df['to_end'] = pd.to_timedelta(df['to_end']).round(timeFormat)\n",
    "df['to_send'] = pd.to_timedelta(df['to_send']).round(timeFormat)\n",
    "df['money_back_date'] = df['money_back_date'].dt.to_period(timeFormat)\n",
    "df['send_at'] = df['send_at'].dt.to_period(timeFormat)\n",
    "df['paid_at'] = df['paid_at'].dt.to_period(timeFormat)\n",
    "df['moderated_at'] = df['moderated_at'].dt.to_period(timeFormat)\n",
    "df['from_date'] = df['from_date'].dt.to_period(timeFormat)\n",
    "df['to_date'] = df['to_date'].dt.to_period(timeFormat)\n",
    "\n",
    "fields = ['id_cr','created_at','transfer_type','type','stat_cr' ,'amount','fee','n_fees','n_backs','good_user',\n",
    "          'stat_fe','id_fe','created_at_fe','updated_at_fe','reason','money_back_date', 'reimbursement_date',\n",
    "          'to_reimbur','from_date','to_date', 'charge_moment' # 'paid_at', 'to_end',, #,'user_id', 'cr_received_date','recovery_status'\n",
    "          #'to_receive_ini','to_receive_bank' #,'to_reimbur_cash', 'updated_at', 'to_send','send_at','moderated_at'\n",
    "]\n",
    "\n",
    "user_id = 2002# 16391 # 2002, 1987, 13851, 16391, 102105\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == user_id])\n",
    "\n",
    "#print(\"Casos segun Cash Request ID\")\n",
    "pd.options.display.max_columns = None\n",
    "for id in ([-8177]): # 16391 20108, 20104, 20112,\n",
    "    df_t = df[df['id_cr'] == id].sort_values(['created_at','created_at_fe']).reset_index()\n",
    "    print(f\"Cash Request ID: {id}\")\n",
    "    display(df_t[fields])\n",
    "\n",
    "user_ids = [user_id] \n",
    "pd.options.display.max_columns = None\n",
    "#print(\"Casos segun Cash User ID\")\n",
    "for id in (user_ids):\n",
    "    df_t = df[(df['user_id'] == id)]#.reset_index()\n",
    "    df_t = df_t[df_t['stat_cr'] == 'money_back']\n",
    "    df_t = df_t[df_t['stat_fe'] == 'accepted']\n",
    "    \n",
    "    df_t = df_t.sort_values(['created_at','created_at_fe']).reset_index(drop=True)\n",
    "    #df_t.set_index('id_cr', inplace=True)\n",
    "    print(f\"Only money_back - user_id {id}\")\n",
    "    display(df_t[fields])\n",
    "    df_t = df[(df['user_id'] == id) ].sort_values(['created_at','created_at_fe']).reset_index(drop=True)\n",
    "\n",
    "    print(f\"user_id {id}\")\n",
    "    display(df_t[fields])\n",
    "\n",
    "#user_ids = [13851] [2002] , 1987, 1946, 90, 526, 12934] #, 12274 54879 12441, 13851, 16391, 430,  63894,18730,10116,21465, 99000262]\n",
    "# vips 12934 526\n",
    "# 90 Este se esta gestionando mal: todos instant, con demoras y sin gestion por \n",
    "# 1946 Parece un ejemplo de buena gestion, al final tiene un instant y se le ha dado margen el las demoras.\n",
    "# 1987 Parece un ejemplo de buen usuario, se pasa a instant para siempre.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_analysis_2 = (\n",
    "    df_jo.groupby(['user_id', 'Mes_created_at'], as_index=False)\n",
    "    .agg(\n",
    "        # Sumar los valores de 'fee' donde 'stat_fe' es igual a 'accepted'\n",
    "        total_paid_fees=('fee', lambda x: x[df_jo.loc[x.index, 'stat_fe'] == 'accepted'].sum()),\n",
    "        \n",
    "        # Contar los valores únicos de 'stat_cr' donde su valor sea 'money_back'\n",
    "        total_paid_cr=('amount', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].unique().sum()),\n",
    "\n",
    "        # Contar los valores únicos de 'id_cr' donde 'stat_cr' es igual a 'money_back'\n",
    "        Num_Solicitudes=('id_cr', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].nunique())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 2002]) ## 13851]) #.tail(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar només les files necessàries per les operacions\n",
    "#filtered_df = df_jo[df_jo['stat_fe'] == 'accepted']\n",
    "filtered_df = df_jo.copy()\n",
    "\n",
    "# Agregar les dades agrupades\n",
    "cohort_analysis_2 = (\n",
    "    filtered_df.groupby(['user_id', 'Mes_created_at'], as_index=False)\n",
    "    .agg(\n",
    "        #total_paid_fees=('fee', 'sum'),\n",
    "        total_paid_fees=('fee', lambda x: x[df_jo.loc[x.index, 'stat_fe'] == 'accepted'].sum()),\n",
    "        total_paid_cr=('amount', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].unique().sum()),\n",
    "        Num_Solicitudes=('id_cr', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].nunique()),\n",
    "        transfer_type=('transfer_type', lambda x: ', '.join(x.unique()))  # Llista valors únics\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 13851]) #.tail(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohort_analysis_3 = filtered_df.groupby(['user_id', 'Mes_created_at'])\n",
    "#display(cohort_analysis_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restablecer el índice para un DataFrame limpio (opcional, ya garantizado por as_index=False)\n",
    "cohort_analysis_2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Calcular el índice como porcentaje entre 'total_paid_fees' y 'total_paid_cr'\n",
    "cohort_analysis_2['index'] = (\n",
    "    cohort_analysis_2['total_paid_fees'] / cohort_analysis_2['total_paid_cr']\n",
    ") * 100\n",
    "\n",
    "# Reemplazar valores 'inf' con 0 para manejar divisiones por cero\n",
    "cohort_analysis_2['index'] = cohort_analysis_2['index'].replace(np.inf, 0)\n",
    "\n",
    "# Calcular la fecha del último pedido por usuario a partir del DataFrame original\n",
    "df_jo['created_at'] = pd.to_datetime(df_jo['created_at'])  # Asegurarse de que el formato sea datetime\n",
    "last_order_per_user = (\n",
    "    df_jo.groupby('user_id')['created_at']\n",
    "    .max()  # Obtener la fecha más reciente de pedido para cada usuario\n",
    "    .dt.to_period('M')  # Convertir a periodo mensual\n",
    "    .reset_index()  # Restablecer el índice para facilitar el merge\n",
    ")\n",
    "\n",
    "# Incorporar la fecha del último pedido en el DataFrame de análisis de cohortes\n",
    "cohort_analysis_2 = pd.merge(\n",
    "    cohort_analysis_2,\n",
    "    last_order_per_user.rename(columns={'created_at': 'last_order'}),\n",
    "    on='user_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Resultado final del DataFrame de análisis de cohortes\n",
    "#cohort_analysis_2\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 13851]) #.tail(60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cohort_analysis_2.info\n",
    "#cohort_analysis_2.count\n",
    "display(cohort_analysis_2[cohort_analysis_2.user_id == 13851]) #.tail(60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear columna 'Cohorte' que indica el mes de la primera solicitud de cada cliente\n",
    "df_jo['Cohorte'] = df_jo.groupby('user_id')['created_at'].transform('min').dt.to_period('M')\n",
    "#df_jo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar los datos por cohorte y mes para calcular las métricas mensuales\n",
    "cohort_analysis = df_jo.groupby(['Cohorte', 'Mes_created_at']).agg(\n",
    "    Num_Clientes=('user_id', 'nunique'),  # Número de clientes únicos por cohorte y mes\n",
    "    Num_Solicitudes=('id_cr', 'nunique'),  # Total de solicitudes únicas por cohorte y mes\n",
    "    Solicitudes_Instant=('transfer_type', lambda x: (x == 'instant').sum()),  # Solicitudes tipo 'instant' por cohorte y mes\n",
    "    Solicitudes_Regular=('transfer_type', lambda x: (x == 'regular').sum()),  # Solicitudes tipo 'regular' por cohorte y mes\n",
    "    Clientes_con_fees=('fee', lambda x: (x > 0).sum()),  # Clientes con fees por cohorte y mes\n",
    "    CR=('id_cr', lambda ids: df_jo[df_jo['id_cr'].isin(ids) & df_jo['cash_request_received_date'].notnull()]['amount'].sum()),\n",
    "\n",
    "    Fees=('fee', 'sum'),  # Total de fees por cohorte y mes\n",
    "    # Contar las líneas con 'stat_fe' == 'accepted'\n",
    "    paid_fees=('stat_fe', lambda x: (x == 'accepted').sum()),  \n",
    "    # Contar las líneas con 'stat_fe' != 'accepted'\n",
    "    non_paid_fees=('stat_fe', lambda x: (x != 'accepted').sum()),\n",
    "    # Sumar 'total_amount' cuando 'stat_fe' == 'accepted'\n",
    "    total_paid_fees=('fee', lambda x: x[df_jo.loc[x.index, 'stat_fe'] == 'accepted'].sum()),\n",
    "    # Sumar 'total_amount' cuando 'stat_fe' != 'accepted'\n",
    "    total_non_paid_fees=('fee', lambda x: x[df_jo.loc[x.index, 'stat_fe'] != 'accepted'].sum()),\n",
    "     # Contar las líneas con 'stat_cr' == 'money_back'\n",
    "    paid_cr=('stat_cr', lambda x: (x == 'money_back').sum()),  \n",
    "    # Contar las líneas con 'stat_fe' != 'accepted'\n",
    "    non_paid_cr=('stat_cr', lambda x: (x != 'money_back').sum()),\n",
    "    # Sumar 'total_amount' cuando 'stat_fe' == 'accepted'\n",
    "    total_paid_cr=('amount', lambda x: x[df_jo.loc[x.index, 'stat_cr'] == 'money_back'].sum()),\n",
    "    # Sumar 'total_amount' cuando 'stat_fe' != 'accepted'\n",
    "    total_non_paid_cr=('amount', lambda x: x[df_jo.loc[x.index, 'stat_cr'] != 'money_back'].sum()),\n",
    "    # Métrica de \"credit lapse\" (diferencia entre reimbursement_date y created_at)\n",
    "    credit_lapse=('reimbursement_date', lambda x: (x - df_jo.loc[x.index, 'created_at']).dt.days.mean()),\n",
    "    # Métrica de \"credit payment lapse\" (diferencia entre money_back_date y reimbursement_date)\n",
    "    credit_payment_lapse=('money_back_date', lambda x: (x - df_jo.loc[x.index, 'reimbursement_date']).dt.days.mean())\n",
    "\n",
    ").reset_index()\n",
    "\n",
    "# Calcular los porcentajes de non_paid_fees\n",
    "cohort_analysis['paid_fees_percent_qty'] = (cohort_analysis['paid_fees'] / (cohort_analysis['paid_fees'] + cohort_analysis['non_paid_fees']))\n",
    "cohort_analysis['paid_fees_percent_amount'] = (cohort_analysis['total_paid_fees'] / cohort_analysis['Fees'])   # % en monto\n",
    "cohort_analysis['paid_cr_percent_qty'] = (cohort_analysis['paid_cr'] / (cohort_analysis['paid_cr'] + cohort_analysis['non_paid_cr']))\n",
    "cohort_analysis['paid_cr_percent_amount'] = (cohort_analysis['total_paid_cr'] / cohort_analysis['CR'])   # % en monto\n",
    "cohort_analysis['index'] = (cohort_analysis['total_paid_fees'] / cohort_analysis['total_paid_cr'])   # % index\n",
    "\n",
    "# Eliminar las columnas de pago y no pago\n",
    "cohort_sizes_monthly = cohort_analysis.drop(\n",
    "    ['paid_fees', 'non_paid_fees', 'total_paid_fees', 'total_non_paid_fees','paid_cr', 'non_paid_cr', 'total_paid_cr', 'total_non_paid_cr'], axis=1, errors='ignore')\n",
    "\n",
    "# Mostrar los resultados de las cohortes por mes\n",
    "#cohort_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_analysis\n",
    "#display(cohort_analysis[cohort_analysis.user_id == 2002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pm.df('df_jo')\n",
    "#df.info()\n",
    "\n",
    "cr_id = ['id_cr','id_fe','user_id', 'created_at','created_at_fe','amount','fee','stat_cr','stat_fe','transfer_type','type',\n",
    "            'to_receive_ini', 'to_receive_bank','to_reimbur','to_reimbur_cash','to_end','to_send',\n",
    "             'send_at', 'cr_received_date', 'money_back_date', 'reimbursement_date',\n",
    "            'paid_at','charge_moment','moderated_at','reason','category','from_date','to_date', 'recovery_status'] # ,'id_y','from_date','to_date','reason','recovery_status', 'cash_request_id'\n",
    "\n",
    "print(\"Casos segun Cash Request ID\")\n",
    "pd.options.display.max_columns = None\n",
    "for id in ([-18264]): # 16391 20108, 20104, 20112,\n",
    "    df_t = df[df['id_cr'] == id].reset_index()\n",
    "    print(f\"Cash Request ID: {id}\")\n",
    "    display(df_t[cr_id].sort_values('created_at'))\n",
    "\n",
    "user_ids = [54879, 9900458, 2002, 1987, 1946, 90, 526, 12934] #, 12274 54879 12441, 13851, 16391, 430,  63894,18730,10116,21465, 99000262]\n",
    "# vips 12934 526\n",
    "# 90 Este se esta gestionando mal: todos instant, con demoras y sin gestion por \n",
    "# 1946 Parece un ejemplo de buena gestion, al final tiene un instant y se le ha dado margen el las demoras.\n",
    "# 1987 Parece un ejemplo de buen usuario, se pasa a instant para siempre.\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "print(\"Casos segun Cash User ID\")\n",
    "for id in (user_ids):\n",
    "    #df_t = df[df['user_id'] == id].reset_index()\n",
    "    df_t = df[(df['user_id'] == id) & (df['stat_cr'] == 'money_back')].reset_index()\n",
    "    print(f\"User ID: {id}\")\n",
    "    display(df_t[cr_id].sort_values('created_at').reset_index())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
