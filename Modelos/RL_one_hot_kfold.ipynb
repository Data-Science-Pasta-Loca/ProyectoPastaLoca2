{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import itertools # Importando itertools para generar combinaciones de columnas\n",
    "# Importando la función seasonal_decompose para la descomposición de series temporales\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import matplotlib.patches as mpatches\n",
    "import payments_manager as pm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# Importa la función para crear la matriz de confusión\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "#cr_cp = pm.df('cr_cp')\n",
    "#fe_cp = pm.df('fe_cp')\n",
    "df_jo = pm.df('df_jo')\n",
    "#df_jo = pm.sort(\"df_jo\", [\"id_cr\"]).reset_index()\n",
    "#df_jo = df_jo.drop(columns=['index'])\n",
    "#df_jo = df_jo.drop(columns=['Mes_created_at'])\n",
    "#df_jo_cp = df_jo.copy()\n",
    "df_jo = pm.sort(\"df_jo\", [\"id_cr\"]).reset_index()\n",
    "df_jo = df_jo.drop(columns=['index'])\n",
    "#df_jo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_jo.copy()\n",
    "# Convertir columnas datetime a timestamps\n",
    "for col in df.select_dtypes(include=['datetime64']).columns:\n",
    "    df[col] = df[col].apply(lambda x: x.timestamp() if pd.notnull(x) else None)\n",
    "\n",
    "for col in df.select_dtypes(include=['timedelta64']).columns:\n",
    "    df[col] = df[col].apply(lambda x: x / pd.to_timedelta(1, unit='d') if pd.notnull(x) else None)\n",
    "\n",
    "df['moderada'] = df['moderated_at'].apply(lambda x: 1 if not pd.isnull(x) else 0)\n",
    "\n",
    "# Variables predictoras (ajusta según los datos disponibles)\n",
    "columnas = ['n_backs','n_fees','n_inc_back','n_inc_fees','n_recovery','n_cr_fe_w', \n",
    "            'amount','fee','to_reimbur', 'type', 'transfer_type','category','charge_moment', 'user_id',\n",
    "            'GBP_EUR', 'BTC_GBP', 'inflation', 'unemploy_rate']\n",
    "\n",
    "#columnas = ['type','transfer_type','category','fee','stat_cr','stat_fe','recovery_status']\n",
    "# type_postpone: 4.9271\n",
    "# n_recovery: 4.4734\n",
    "# type_instant_payment: -3.2748\n",
    "# n_fees: -1.5516\n",
    "# transfer_type_regular: -1.5466\n",
    "# n_cr_fe_w: -1.3381\n",
    "# n_backs: -1.2269\n",
    "# category_nice: 1.1226\n",
    "# type_incident: 1.1137\n",
    "# n_inc_fees: 1.1103\n",
    "# n_inc_back: 0.9395\n",
    "# fee: 0.8886\n",
    "\n",
    "\n",
    "X = df[columnas].copy()\n",
    "\n",
    "# Categoricas\n",
    "#X = pd.get_dummies(X, columns=['type', 'transfer_type', 'category','stat_cr','stat_fe','recovery_status'], drop_first=True, dtype =int)\n",
    "X = pd.get_dummies(X, columns=['type', 'transfer_type', 'category','charge_moment'], drop_first=True, dtype =int)\n",
    "#X = pd.get_dummies(X, columns=['category'], drop_first=True, dtype =int)\n",
    "\n",
    "# Crear el escalador\n",
    "display(X.head(1))\n",
    "scaler = StandardScaler()\n",
    "# Estandarizar todas las columnas\n",
    "normalizado = scaler.fit_transform(X)\n",
    "# Convertir de nuevo a DataFrame, preservando nombres de columnas e índices\n",
    "X = pd.DataFrame(normalizado, columns=X.columns, index=df.index)\n",
    "X.fillna(0, inplace=True)\n",
    "#X.info()\n",
    "\n",
    "\n",
    "y = df['needs_m_check_recov'].copy()  #moderada # La columna de la variable objetivo\n",
    "#display(X.head(2))\n",
    "\n",
    "feature_names = X.columns # Obtener los nombres de las características\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "# Crea el clasificador de regresión logística. El 'liblinear' usa metodo de optimización de minimos cuadrados generalizados (L2) y soporta la regularización L1 y L2\n",
    "clf = LogisticRegression(solver=\"liblinear\")\n",
    "clf.fit(X_train, y_train) # Entrena el clasificador\n",
    "predicciones = clf.predict(X_test) # Realiza predicciones sobre el conjunto de prueba\n",
    "\n",
    "# Genera las probabilidades de predicción\n",
    "predicciones_probabilidades = clf.predict_proba(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada k-fold divide los datos en k subconjuntos (folds), entrena el modelo en k-1 subconjuntos y lo valida en el subconjunto restante. Este proceso se repite k veces, usando cada subconjunto como validación una vez. El resultado final es el promedio de los errores obtenidos en las k iteraciones.\n",
    "\n",
    "Pasos para Implementar k-Fold en Regresión Logística\n",
    "\n",
    "1. Importar las Bibliotecas Necesarias: Asegúrate de usar scikit-learn, que tiene herramientas integradas para validación cruzada.\n",
    "2. Preparar los Datos: Los datos deben estar limpios y preprocesados, como lo hiciste anteriormente.\n",
    "3. Configurar el Modelo: Define el modelo de regresión logística.\n",
    "4. Realizar la Validación k-Fold: Utiliza cross_val_score para calcular las métricas de rendimiento (por ejemplo, precisión, exactitud, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "# Configura el modelo de regresión logística\n",
    "#clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Configura la validación cruzada k-fold\n",
    "k = 5  # Número de folds\n",
    "kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Métrica personalizada (por ejemplo, F1-score)\n",
    "scoring = make_scorer(f1_score)\n",
    "\n",
    "# Realiza la validación cruzada y calcula la métrica para cada fold\n",
    "scores = cross_val_score(clf, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"F1-scores en cada fold: {scores}\")\n",
    "print(f\"F1-score promedio: {scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar del F1-score: {scores.std():.4f}\")\n",
    "\n",
    "# Gráfico de las métricas obtenidas en cada fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, k + 1), scores, color=\"skyblue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.axhline(scores.mean(), color=\"red\", linestyle=\"--\", label=\"Promedio\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"Validación Cruzada k-Fold\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea un histograma de las probabilidades de predicción para ambas clases\n",
    "plt.figure(figsize=(10, 6)) \n",
    "plt.hist(predicciones_probabilidades[:, 0], bins=20, color=\"skyblue\", edgecolor=\"black\", alpha=0.3, label=\"Necesita Manual check\")\n",
    "# Histograma para la clase positiva (no need manual check)\n",
    "plt.hist(predicciones_probabilidades[:, 1], bins=20, color=\"salmon\", edgecolor=\"black\", alpha=0.3, label=\"No necesita Manual check\")\n",
    "# Título y etiquetas de los ejes\n",
    "plt.title(\"Distribución de Probabilidades de Predicción para Ambas Clases\")\n",
    "plt.xlabel(\"Probabilidad de Predicción\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.legend(loc=\"upper center\") \n",
    "# Muestra la leyenda en el gráfico\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.1)\n",
    "plt.show()\n",
    "\n",
    "# Muestra las primeras 10 probabilidades de predicción\n",
    "print(f\"predicciones_probabilidades:\\n {predicciones_probabilidades[:10]}\\n\")\n",
    "\n",
    "# Obtén los coeficientes y asigna los nombres de las características\n",
    "coeficientes = clf.coef_[0]  # clf.coef_ es un array bidimensional, tomamos la primera fila\n",
    "feature_coef = list(zip(feature_names, coeficientes))\n",
    "\n",
    "# Ordena las características por el valor absoluto del coeficiente en orden descendente\n",
    "feature_coef_sorted = sorted(feature_coef, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Imprime cada variable junto con su coeficiente ordenado\n",
    "print(\"Coeficientes del modelo de regresión logística (ordenados por magnitud):\")\n",
    "for feature, coef in feature_coef_sorted:\n",
    "    print(f\"{feature}: {coef:.4f}\")\n",
    "\n",
    "# Genera la matriz de confusión\n",
    "matriz_confusion = confusion_matrix(y_test, predicciones)\n",
    "columnas = ['no_needs_m_check', 'needs_m_check'] # 0 para No necesita manual check y 1 para Sí necesita manual check\n",
    "\n",
    "# Visualiza la matriz de confusión utilizando un mapa de calor\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(matriz_confusion, annot=True, fmt='d', cmap='Blues', xticklabels=columnas, yticklabels=columnas)\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Realidad\")\n",
    "plt.show()\n",
    "# Evaluate model performance\n",
    "print(\"Accuracy:\", clf.score(X_test, y_test))  # Accuracy score\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predicciones))  # Classification report\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_test, predicciones_probabilidades[:, 1])\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc(fpr, tpr):.2f}\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, f1_score\n",
    "\n",
    "# Configura el modelo de regresión logística\n",
    "#clf = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Configura la validación cruzada k-fold\n",
    "k = 5  # Número de folds\n",
    "kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Métrica personalizada (por ejemplo, F1-score)\n",
    "scoring = make_scorer(f1_score)\n",
    "\n",
    "# Realiza la validación cruzada y calcula la métrica para cada fold\n",
    "scores = cross_val_score(clf, X, y, cv=kfold, scoring=scoring)\n",
    "\n",
    "# Imprime los resultados\n",
    "print(f\"F1-scores en cada fold: {scores}\")\n",
    "print(f\"F1-score promedio: {scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar del F1-score: {scores.std():.4f}\")\n",
    "\n",
    "# Gráfico de las métricas obtenidas en cada fold\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, k + 1), scores, color=\"skyblue\", edgecolor=\"black\", alpha=0.7)\n",
    "plt.axhline(scores.mean(), color=\"red\", linestyle=\"--\", label=\"Promedio\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.title(\"Validación Cruzada k-Fold\")\n",
    "plt.legend()\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the cross-validation procedure\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "# evaluate a logistic regression model using repeated k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# prepare the cross-validation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# create model\n",
    "#clf = LogisticRegression()\n",
    "# evaluate model\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the number of repeats for repeated k-fold cross-validation\n",
    "from scipy.stats import sem\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# evaluate a model with a given number of repeats\n",
    "def evaluate_model(X, y, repeats):\n",
    "\t# prepare the cross-validation procedure\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=repeats, random_state=1)\n",
    "\t# create model\n",
    "\t#model = LogisticRegression()\n",
    "\t# evaluate model\n",
    "\tscores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    " \n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# configurations to test\n",
    "repeats = range(1,16)\n",
    "results = list()\n",
    "for r in repeats:\n",
    "\t# evaluate using a given number of repeats\n",
    "\tscores = evaluate_model(X, y, r)\n",
    "\t# summarize\n",
    "\tprint('>%d mean=%.4f se=%.3f' % (r, mean(scores), sem(scores)))\n",
    "\t# store\n",
    "\tresults.append(scores)\n",
    "# plot the results\n",
    "pyplot.boxplot(results, labels=[str(r) for r in repeats], showmeans=True)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
