{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de bibliotecas estándar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importación de bibliotecas para visualización\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Importación de herramientas para modelos de machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn import tree\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve, KFold, GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# Librerías adicionales\n",
    "import itertools  # Para generar combinaciones de columnas\n",
    "import matplotlib.patches as mpatches  # Para manejar gráficos\n",
    "\n",
    "# Importación de módulo personalizado\n",
    "import payments_manager as pm\n",
    "\n",
    "# Inicialización del proyecto (si es necesario)\n",
    "# pm.help()  # Si se necesita ayuda del módulo\n",
    "# pm.reset()  # Para reiniciar cualquier configuración anterior\n",
    "# pm.init()  # Si es necesario inicializar el módulo con opciones (por ejemplo, debug=True)\n",
    "\n",
    "# Cargar y preparar el DataFrame df_jo\n",
    "df_jo = pm.df('df_jo')  # Cargar el DataFrame desde 'payments_manager'\n",
    "df_jo.info()  # Ver información básica sobre el DataFrame\n",
    "\n",
    "# Ordenar el DataFrame df_jo por la columna 'id_cr' y resetear índices\n",
    "df_jo = df_jo.sort_values(by=[\"id_cr\"]).reset_index(drop=True)\n",
    "\n",
    "# Crear una copia del DataFrame para su posterior uso\n",
    "df_jo_cp = df_jo.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASAJE DE CATEGORICAS A NUMERICAS\n",
    "\n",
    "# Reasignar valores en la columna 'transfer_type'\n",
    "df_jo_cp['transfer_type'] = df_jo_cp['transfer_type'].map({'regular': 0, 'instant': 1})\n",
    "df_jo_cp['charge_moment'] = df_jo_cp['charge_moment'].map({'before': 0, 'after': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEGMENTACIONES EN DATAFRAMES REPETITIVOS Y NUEVOS\n",
    "\n",
    "# Ordenar por 'created_at' para asegurar que la primera acción esté en la parte superior\n",
    "df_jo_cp_sorted = df_jo_cp.sort_values('created_at')\n",
    "count_all = df_jo_cp_sorted.shape[0]\n",
    "\n",
    "# 2. Identificar usuarios con más de una acción (usuarios repetitivos)\n",
    "\n",
    "repeat_users_df = df_jo_cp[(df_jo_cp['n_fees'] > 1) | (df_jo_cp['n_backs'] > 1) | (df_jo_cp['n_recovery'] > 1) | (df_jo_cp['n_inc_back'] > 1)| (df_jo_cp['n_inc_fees'] > 1)]\n",
    "\n",
    "# Sort and group by user_id, keeping repetitive activities\n",
    "repeat_users_df = repeat_users_df.sort_values('created_at').reset_index(drop=True)\n",
    "\n",
    "# Obtener los usuarios nuevos (aquellos con solo una acción)\n",
    "\n",
    "new_users_df = df_jo_cp[(df_jo_cp['n_fees'] <= 1) & (df_jo_cp['n_backs'] <= 1) & (df_jo_cp['n_recovery'] <= 1) & (df_jo_cp['n_inc_back'] <= 1) & (df_jo_cp['n_inc_fees'] <= 1)]\n",
    "\n",
    "\n",
    "new_users_df = new_users_df.sort_values('created_at').groupby('user_id').first().reset_index()\n",
    "\n",
    "# Número de filas de nuevos usuarios\n",
    "count_new_users = new_users_df.shape[0]\n",
    "\n",
    "# Número de filas de usuarios repetitivos\n",
    "count_repeat_users = repeat_users_df.shape[0]\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f'Número de filas en el DataFrame original: {count_all}')\n",
    "print(f'Número de filas en el DataFrame de nuevos usuarios: {count_new_users}')\n",
    "print(f'Número de filas en el DataFrame de usuarios repetitivos: {count_repeat_users}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VERIFICACION DE BALANCEO DE CLASES\n",
    "\n",
    "# Obtener el conteo de los valores únicos en la columna 'needs_m_check_recov'\n",
    "value_counts_all = df_jo_cp['needs_m_check_recov'].value_counts()\n",
    "value_counts_new = new_users_df['needs_m_check_recov'].value_counts()\n",
    "value_counts_rep = repeat_users_df['needs_m_check_recov'].value_counts()\n",
    "\n",
    "# Calcular el total de operaciones (suma de las dos categorías)\n",
    "total_all = value_counts_all[0] + value_counts_all[1]\n",
    "total_new = value_counts_new[0] + value_counts_new[1]\n",
    "total_rep = value_counts_rep[0] + value_counts_rep[1]\n",
    "\n",
    "# Calcular el porcentaje de operaciones con 'needs_m_check' (cuando es 1)\n",
    "needs_manual_all = (value_counts_all[1] / total_all) * 100\n",
    "needs_manual_new = (value_counts_new[1] / total_new) * 100\n",
    "needs_manual_rep = (value_counts_rep[1] / total_rep) * 100\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f'Porcentaje de operaciones con needs_m_check del total de clientes: {needs_manual_all:.2f} %')\n",
    "print(f'Porcentaje de operaciones con needs_m_check del clientes nuevos: {needs_manual_new:.2f} %')\n",
    "print(f'Porcentaje de operaciones con needs_m_check del clientes repetitivos: {needs_manual_rep:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas que deseas seleccionar del df_jo para el MODELO\n",
    "columnas_deseadas = ['created_at_slot', 'created_at_dow' ,'transfer_type','n_recovery', 'n_fees', 'n_backs','n_inc_back','n_inc_fees','GBP_EUR','BTC_GBP','inflation', 'unemploy_rate','amount','charge_moment','needs_m_check_recov']\n",
    "\n",
    "# Crear un nuevo DataFrame solamente con esas columnas\n",
    "#df_simpl = df_jo_cp_sorted[columnas_deseadas]\n",
    "#df_simpl = new_users_df[columnas_deseadas]\n",
    "df_simpl = repeat_users_df[columnas_deseadas]\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "m_corr_simpl = df_simpl.corr()\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(m_corr_simpl, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Matriz de Correlación Simple')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BALANCEO DE CARGAS\n",
    "\n",
    "columns = df_simpl.columns\n",
    "X_b = df_simpl.drop('needs_m_check_recov', axis=1)\n",
    "y_b = df_simpl['needs_m_check_recov']\n",
    "\n",
    "undersample = RandomUnderSampler()\n",
    "X_under, y_under = undersample.fit_resample(X_b, y_b)\n",
    "\n",
    "columns_X = np.delete(columns, 14)\n",
    "columns_y = columns[-1]\n",
    "\n",
    "print(pd.Series(y_under).value_counts())\n",
    "\n",
    "X_b_df = pd.DataFrame(X_under, columns=columns_X)\n",
    "y_b_df = pd.DataFrame(y_under, columns=[columns_y])\n",
    "\n",
    "balanced_df = pd.concat([X_b_df, y_b_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZACION Y ESCALADO\n",
    "\n",
    "# Eliminar las columnas no necesarias del DataFrame\n",
    "X_s = balanced_df.drop(columns=[\n",
    "    'needs_m_check_recov',\n",
    "])\n",
    "\n",
    "# Definir la variable objetivo\n",
    "Y_s = balanced_df['needs_m_check_recov']\n",
    "\n",
    "# Aplicar StandardScaler para la normalización\n",
    "s_scaler = StandardScaler()\n",
    "X_s_scaled = s_scaler.fit_transform(X_s)\n",
    "\n",
    "# Convertir el array escalado de nuevo a DataFrame y restaurar los nombres de las columnas\n",
    "X_s_scaled = pd.DataFrame(X_s_scaled, columns=X_s.columns)\n",
    "\n",
    "# Imprimir las formas de los datos\n",
    "print(X_s_scaled.shape)\n",
    "print(Y_s.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARACION DE CARACTERISTICAS Y ETIQUETA PARA MODELOS\n",
    "\n",
    "# Crea la matriz de características y la var objetivo\n",
    "#X = df_simpl.drop(columns=[\n",
    "#    'needs_m_check_recov',  \n",
    "    #'created_at_slot',      \n",
    "    #'created_at_dow',       \n",
    "    #'transfer_type',\n",
    "    #'n_fees',\n",
    "    #'n_backs',\n",
    "    #'n_inc_back',\n",
    "    #'n_inc_fees',\n",
    "    #'GBP_EUR',\n",
    "    #'BTC_GBP',\n",
    "    #'inflation',      \n",
    "    #'unemploy_rate',\n",
    "    #'amount',\n",
    "    #'charge_moment\"\n",
    "    #'n_recovery\"\n",
    "#])\n",
    "\n",
    "X = X_s.drop(columns=[\n",
    "    #  'created_at_slot',      \n",
    "    #  'created_at_dow',       \n",
    "    #  'transfer_type',\n",
    "    #  'n_fees',\n",
    "    #  'n_backs',\n",
    "    #  'n_inc_back',\n",
    "    #  'n_inc_fees',\n",
    "    #  'GBP_EUR',\n",
    "    #  'BTC_GBP',\n",
    "    #  'inflation',      \n",
    "    #  'unemploy_rate',\n",
    "    #  'amount',\n",
    "    #  'charge_moment'\n",
    "    #  'n_recovery\"\n",
    "])\n",
    "\n",
    "#y = df_simpl['needs_m_check_recov'] # La columna de la variable objetivo\n",
    "y = Y_s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELO DE ÁRBOL DE DECISIÓN/RANDOM FOREST\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo de Árbol de Decisión\n",
    "#DT = tree.DecisionTreeClassifier(min_samples_leaf=5, max_depth=None)\n",
    "RF = RandomForestClassifier(\n",
    "    n_estimators=200,            # Número de árboles en el bosque\n",
    "    max_depth=14,              # Profundidad máxima de los árboles\n",
    "    min_samples_split=5,         # Mínimo número de muestras requeridas para dividir un nodo interno\n",
    "    min_samples_leaf=1,          # Mínimo número de muestras requeridas en una hoja\n",
    "    max_features='sqrt',         # Número máximo de características consideradas en cada división \n",
    "    class_weight='balanced',     # Ajusta automáticamente los pesos para manejar el desbalanceo de clases\n",
    "    criterion='log_loss',            # Métrica para medir la calidad de las divisiones\n",
    "    bootstrap=True,              # Usa muestreo con reemplazo para construir cada árbol\n",
    "    random_state=42,             # Semilla para reproducibilidad de resultados\n",
    "    oob_score=True               # Activa la estimación de rendimiento con datos fuera de la bolsa (out-of-bag)\n",
    ")\n",
    "\n",
    "\n",
    "# Entrenar el modelo con el conjunto de datos de entrenamiento\n",
    "#DT.fit(X_train, y_train)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "#predictions = DT.predict(X_test)\n",
    "predictions = RF.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de las características\n",
    "feature_importances = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': RF.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUACION DEL RENDIMIENTO DEL MODELO\n",
    "\n",
    "# 1. Precisión del modelo\n",
    "accuracy = RF.score(X_test, y_test)\n",
    "print(f\"Precisión del modelo: {accuracy:.4f}\")  # Precisión en el conjunto de prueba\n",
    "\n",
    "# 2. Reporte de clasificación\n",
    "print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, predictions))  \n",
    "# Muestra el reporte con métricas como precisión, recall, f1-score para cada clase\n",
    "\n",
    "# 3. Importancia de las características\n",
    "\n",
    "# Extraer los nombres de las características\n",
    "feature_names = X.columns\n",
    "\n",
    "# Obtener las importancias de las características del modelo\n",
    "feature_importances = RF.feature_importances_\n",
    "\n",
    "# Crear una lista de tuplas con el nombre de la característica y su importancia\n",
    "feature_importance = list(zip(feature_names, feature_importances))\n",
    "\n",
    "# Ordenar las características por la importancia en orden descendente\n",
    "feature_importance_sorted = sorted(feature_importance, key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Imprimir las características ordenadas por importancia\n",
    "print(\"\\nImportancia de las características (ordenadas por magnitud):\")\n",
    "for feature, importance in feature_importance_sorted:\n",
    "    print(f\"{feature}: {importance:.4f}\")\n",
    "\n",
    "# 4. Visualización de la importancia de las características\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Graficar las importancias de las características (ordenadas)\n",
    "features = [f[0] for f in feature_importance_sorted]\n",
    "importances = [f[1] for f in feature_importance_sorted]\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.barh(features, importances, color='lightblue')\n",
    "plt.xlabel(\"Importancia\")\n",
    "plt.title(\"Importancia de las Características en el Modelo de Árbol de Decisión\")\n",
    "plt.show()\n",
    "\n",
    "# 5. Matriz de confusión\n",
    "\n",
    "# Nombres de las clases para la matriz de confusión\n",
    "columnas = ['no_needs_m_check', 'needs_m_check']  # 0 = No, 1 = Sí\n",
    "\n",
    "# Visualización de la matriz de confusión con un mapa de calor\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix(y_test, predictions), annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=columnas, yticklabels=columnas)\n",
    "\n",
    "# Personalización de los ejes\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Realidad\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar curvas de error. \n",
    "\n",
    "np.random.seed(42)\n",
    "# Parámetros\n",
    "MAXN = 500 #len(X)  # Total de muestras disponibles\n",
    "steps = 10  # Tamaño de incremento del conjunto de entrenamiento\n",
    "iterations = 10  # Número de iteraciones para suavizar los resultados\n",
    "print(f\"Total de muestras: {MAXN}\")\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#display(X_test)\n",
    "#display(y_test)\n",
    "\n",
    "print(f\"{(MAXN // steps) * steps + 0 }\")\n",
    "\n",
    "# Calcular el número de columnas\n",
    "cols = list(range(steps, (MAXN // steps) * steps, steps))\n",
    "\n",
    "# Inicializamos los DataFrames para almacenar los errores\n",
    "test_errors = pd.DataFrame(np.zeros((iterations, len(cols))), columns=cols)\n",
    "train_errors = pd.DataFrame(np.zeros((iterations, len(cols))), columns=cols)\n",
    "\n",
    "# Generamos los errores promedios por iteración\n",
    "for iteration in range(iterations):\n",
    "    # Mezclamos los datos\n",
    "    data = pd.concat([X, y], axis=1).sample(frac=1).reset_index(drop=True)\n",
    "    X_shuffled = data[X.columns]\n",
    "    y_shuffled = data[y.name]\n",
    "    \n",
    "    for N in range(steps, MAXN, steps):\n",
    "        j = (N // steps) - 1  # Índice para almacenar resultados\n",
    "        \n",
    "        # Tomar un subconjunto de datos para entrenamiento\n",
    "        X_subset = X_shuffled.iloc[:N, :]\n",
    "        y_subset = y_shuffled.iloc[:N]\n",
    "        \n",
    "        RF = RandomForestClassifier(\n",
    "            n_estimators=200,            # Número de árboles en el bosque\n",
    "            max_depth=14,              # Profundidad máxima de los árboles\n",
    "            min_samples_split=5,         # Mínimo número de muestras requeridas para dividir un nodo interno\n",
    "            min_samples_leaf=1,          # Mínimo número de muestras requeridas en una hoja\n",
    "            max_features='sqrt',         # Número máximo de características consideradas en cada división \n",
    "            class_weight='balanced',     # Ajusta automáticamente los pesos para manejar el desbalanceo de clases\n",
    "            criterion='log_loss',            # Métrica para medir la calidad de las divisiones\n",
    "            bootstrap=True,              # Usa muestreo con reemplazo para construir cada árbol\n",
    "            random_state=42,             # Semilla para reproducibilidad de resultados\n",
    "            oob_score=True               # Activa la estimación de rendimiento con datos fuera de la bolsa (out-of-bag)\n",
    "        )\n",
    "        RF.fit(X_subset, y_subset)\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de prueba y calcular la tasa de error.\n",
    "        test_errors.iloc[iteration, j] = 1 - metrics.accuracy_score(RF.predict(X_test), y_test)\n",
    "        # Evaluar el modelo en el conjunto de entrenamiento y calcular la tasa de error.\n",
    "        train_errors.iloc[iteration, j] = 1 - metrics.accuracy_score(RF.predict(X_subset), y_subset)\n",
    "\n",
    "# Promediar las tasas de error a lo largo de las iteraciones para obtener una curva de aprendizaje más estable.\n",
    "mean_test_error = test_errors.mean(axis=0)\n",
    "mean_train_error = train_errors.mean(axis=0)\n",
    "\n",
    "# Graficar las curvas de aprendizaje: tasa de error en prueba y entrenamiento.\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(mean_test_error, 'r', label='Error en Prueba') # Error en el conjunto de prueba.\n",
    "plt.plot(mean_train_error, 'b', label='Error en Entrenamiento') # Error en el conjunto de entrenamiento.\n",
    "\n",
    "# Configurar etiquetas, título y leyenda.\n",
    "plt.xlabel('Número de muestras x10', fontsize=12)\n",
    "plt.ylabel('Tasa de Error', fontsize=12)\n",
    "plt.title('Curvas de Aprendizaje para RandomForest', fontsize=14)\n",
    "plt.legend(loc='upper left', fontsize=12, bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Mostrar la gráfica con las curvas de error.\n",
    "plt.grid(True)\n",
    "plt.tight_layout() # Ajustar la distribución para evitar que las etiquetas se corten.\n",
    "plt.show()\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = X.to_numpy()\n",
    "y_np = y.to_numpy()\n",
    "\n",
    "# Configurar la validación cruzada de 10 pliegues\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Definir los hiperparámetros a evaluar\n",
    "C = np.arange(2, 20)\n",
    "\n",
    "# Matriz para almacenar las precisiones\n",
    "results = np.zeros((10, len(C)))\n",
    "\n",
    "# Iterar sobre los pliegues y los hiperparámetros\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(X_np)):\n",
    "    X_train, X_val = X_np[train_idx], X_np[val_idx]\n",
    "    y_train, y_val = y_np[train_idx], y_np[val_idx]\n",
    "    for i, c in enumerate (C):\n",
    "\n",
    "        RF = RandomForestClassifier(\n",
    "            n_estimators=200,            # Número de árboles en el bosque\n",
    "            max_depth=c,              # Profundidad máxima de los árboles\n",
    "            min_samples_split=5,         # Mínimo número de muestras requeridas para dividir un nodo interno\n",
    "            min_samples_leaf=1,          # Mínimo número de muestras requeridas en una hoja\n",
    "            max_features='sqrt',         # Número máximo de características consideradas en cada división \n",
    "            class_weight='balanced',     # Ajusta automáticamente los pesos para manejar el desbalanceo de clases\n",
    "            criterion='gini',            # Métrica para medir la calidad de las divisiones\n",
    "            bootstrap=True,              # Usa muestreo con reemplazo para construir cada árbol\n",
    "            random_state=42,             # Semilla para reproducibilidad de resultados\n",
    "            oob_score=True               # Activa la estimación de rendimiento con datos fuera de la bolsa (out-of-bag)\n",
    "        )\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        RF.fit(X_train, y_train)\n",
    "\n",
    "        # Predecir resultados\n",
    "        y_pred = RF.predict(X_val)\n",
    "\n",
    "        # Calcular y almacenar la precisión\n",
    "        results[fold, i] = accuracy_score(y_val, y_pred)\n",
    "\n",
    "# Graficar los resultados\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.boxplot(results, vert=True, patch_artist=True, meanline=True)\n",
    "\n",
    "# Superponer los puntajes de precisión individuales para cada nivel de complejidad.\n",
    "for i, c in enumerate(C):  # Usar el valor de C en lugar del índice.\n",
    "    xderiv = (i + 1) * np.ones(results[:, i].shape) + (np.random.rand(10,) - 0.5) * 0.1\n",
    "    plt.plot(xderiv, results[:, i], 'ro', alpha=0.3)  # 'ro' indica marcadores de círculo rojo.\n",
    "\n",
    "# Establecer etiquetas para el eje x con los valores reales de C.\n",
    "plt.xticks(ticks=np.arange(1, len(C) + 1), labels=C)\n",
    "plt.xlabel('Complejidad del Árbol (max_depth)', fontsize=12)\n",
    "plt.ylabel('Precisión', fontsize=12)\n",
    "plt.title('Precisión del Random Forest para Diferentes Hiperparámetros', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los hiperparámetros a probar y sus valores\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # Número de árboles\n",
    "    'max_depth': [None, 10, 20, 30],       # Profundidad máxima de los árboles\n",
    "    'min_samples_split': [2, 5, 10],       # Mínimas muestras para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4],         # Mínimas muestras en una hoja\n",
    "    'max_features': ['sqrt', 'log2'],      # Número máximo de características para cada división\n",
    "    'class_weight': ['balanced', None]     # Peso para manejar desbalanceo\n",
    "}\n",
    "\n",
    "# Inicializar el modelo base\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model, \n",
    "    param_grid=param_grid, \n",
    "    cv=3,                 # Validación cruzada con 3 pliegues\n",
    "    scoring='f1_weighted',  # Utilizamos F1 ponderado como métrica de evaluación\n",
    "    verbose=1,            # Mostrar el progreso\n",
    "    n_jobs=-1             # Usar todos los núcleos disponibles\n",
    ")\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y puntaje\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor precisión en validación cruzada:\", grid_search.best_score_)\n",
    "\n",
    "# Entrenar el modelo con los mejores parámetros encontrados\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo con el conjunto de prueba\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "print(\"Reporte de clasificación con parámetros ajustados:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
